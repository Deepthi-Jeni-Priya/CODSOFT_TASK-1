{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "%matplotlib inline \nimport numpy as np \nimport scipy as sp \nimport matplotlib as mpl\nimport matplotlib.cm as cm \nimport matplotlib.pyplot as plt\nimport pandas as pd \n#from pandas.tools.plotting import scatter_matrix\npd.set_option('display.width', 500)\npd.set_option('display.max_columns', 100)\npd.set_option('display.notebook_repr_html', True)\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nimport warnings\nwarnings.filterwarnings('ignore')\nimport string\nimport math\nimport sys\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport sklearn\nfrom IPython.core.interactiveshell import InteractiveShell\n\nInteractiveShell.ast_node_interactivity = \"all",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/titanic/train.csv')\nTest = pd.read_csv(\"../input/titanic/test.csv\")\n\ncombine = [train, Test]\ncombined = pd.concat(combine)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train.tail()\ntrain.info()\n\nprint('_'*40)\n\nTest.info()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train.count()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print('Train columns with null values:',train.isnull().sum(), sep = '\\n')\nprint(\"-\"*42)\n\n\nprint('Test/Validation columns with null values:', Test.isnull().sum(),sep = '\\n')\nprint(\"-\"*42)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "rain.describe(include='all')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, survive_bar = plt.subplots(figsize=(7, 7))\nsns.barplot(x= train[\"Survived\"].value_counts().index, y = train[\"Survived\"].value_counts(), ax = survive_bar)\nsurvive_bar.set_xticklabels(['Not Survived', 'Survived'])\nsurvive_bar.set_ylabel('Frequency Count')\nsurvive_bar.set_title('Count of Survival', fontsize = 16)\n\nfor patch in survive_bar.patches:\n    label_x = patch.get_x() + patch.get_width()/2  # find midpoint of rectangle\n    label_y = patch.get_y() + patch.get_height()/2\n    survive_bar.text(label_x, label_y,\n                #left - freq below - rel freq wrt population as a percentage\n               str(int(patch.get_height())) + '(' +\n               '{:.0%}'.format(patch.get_height()/len(train.Survived))+')',\n               horizontalalignment='center', verticalalignment='center')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, embarked_bar = plt.subplots(figsize=(7, 7))\nsns.barplot(x= train[\"Embarked\"].value_counts().index, y = train[\"Embarked\"].value_counts(), ax = embarked_bar)\nembarked_bar.set_xticklabels(['Southampton', 'Chernboug', 'Queenstown'])\nembarked_bar.set_ylabel('Frequency Count')\nembarked_bar.set_title('Where did the passengers board the Titanic?', fontsize = 16)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "fig, myplot = plt.subplots(figsize = (15,6), nrows = 2,ncols = 3)\n\ncategorical_features = [\"Survived\",\"Pclass\",\"Sex\",\"SibSp\",\"Parch\",\"Embarked\"]\n\nrow, col, num_cols = 0,0,3\n\nfor u in categorical_features:\n    sns.barplot(x = train[u].value_counts().index,y = train[u].value_counts(), ax  = myplot[row, col])\n    myplot[row, col].set_xlabel(\"\")\n    myplot[row, col].set_title(u + \" Titanic\", fontsize = 15)\n    myplot[row, col].set_ylabel(\"Count\")\n    col = col + 1\n    if col == 3:\n        col = 0\n        row = row + 1plt.subplots_adjust(hspace = 0.5)\nplt.subplots_adjust(wspace = 0.3)\n# i put roundbracket around x,y,z to make more sense. just like how x \\in [1,2,3] and if x is a tuple or bracket\n#we have   u \\in [(1,2,3),(2,3,5),...] where u = (x,y,z)\n\n#for each patch in each graph from [0,0] to [1,2], we want to do the following...\nfor v in range(2):\n    for z in range(3):\n        for patch in myplot[v,z].patches:\n            label_x = patch.get_x() + patch.get_width()/2  # find midpoint of rectangle\n            label_y = patch.get_y() + patch.get_height()/2\n            myplot[v,z].text(label_x, label_y, \n                             str(int(patch.get_height())) + '('+'{:.0%}'.format(patch.get_height()/len(train.Survived))+')',\n                            horizontalalignment='center', verticalalignment='center')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "null_ages = pd.isnull(train.Age)\nknown_ages = pd.notnull(train.Age)\npreimputation = train.Age[known_ages]\nsns.distplot(preimputation)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, myaxis = plt.subplots(figsize=(10, 4.5))\n\nsns.kdeplot(data=train[\"Age\"], kernel='gau', ax=myaxis, color=\"Red\", shade=True, legend=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "f,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(train.corr(), annot=True, linewidths=0.5, fmt='.2f',ax=ax)\nax.set_ylim(7, 0)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def print_percentage(df,col_name,col_values):\n    for x in col_values:\n        group = df.loc[df[col_name]==x]\n        print ('{0} survival rate: {1:.3f}'.format(x, (group['Survived'].sum()/group.shape[0])))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print_percentage(train,'Sex',[\"male\",\"female\"])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "igure, myaxis = plt.subplots(figsize=(10, 7.5))\n\n\nsns.barplot(x = \"Sex\", \n            y = \"Survived\", \n            data=train, \n            ax = myaxis,\n            estimator = np.mean,\n            palette = {'male':\"green\", 'female':\"Pink\"},\n            linewidth=2)\n\nmyaxis.set_title(\"Survived/Non-Survived Passenger Gender Distribution\", fontsize = 20)\nmyaxis.set_xlabel(\"Sex\",fontsize = 15)\nmyaxis.set_ylabel(\"Proportion of passengers survived\", fontsize = 15)\n\nfor patch in myaxis.patches:\n    label_x = patch.get_x() + patch.get_width()/2  # find midpoint of rectangle\n    label_y = patch.get_y() + patch.get_height()/2\n    myaxis.text(label_x, label_y,\n                #left - freq below - rel freq wrt population as a percentage\n                '{:.3%}'.format(patch.get_height()),\n               horizontalalignment='center', verticalalignment='center')\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, myaxis = plt.subplots(figsize=(10, 7.5))\n\nsns.countplot(x = \"Sex\", \n                   hue=\"Survived\",\n                   data = train, \n                   linewidth=2, \n                   palette = {1:\"seagreen\", 0:\"gray\"}, ax = myaxis)\n\n\n## Fixing title, xlabel and ylabel\nmyaxis.set_title(\"Passenger Gender Distribution - Survived vs Not-survived\", fontsize = 20)\nmyaxis.set_xlabel(\"Sex\", fontsize = 15);\nmyaxis.set_ylabel(\"Number of Passenger Survived\", fontsize = 15)\nmyaxis.legend([\"Not Survived\", \"Survived\"], loc = 'upper right')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print_percentage(train,'Pclass',[1,2,3])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, pclass_bar = plt.subplots(figsize = (8,10))\nsns.barplot(x = \"Pclass\", \n            y = \"Survived\", \n            estimator = np.mean,\n            data=train, \n            ax = pclass_bar,\n            linewidth=2)\npclass_bar.set_title(\"Passenger Class Distribution - Survived vs Non-Survived\", fontsize = 18)\npclass_bar.set_xlabel(\"Passenger class (Pclass)\", fontsize = 15);\npclass_bar.set_ylabel(\"% of Passenger Survived\", fontsize = 15);\nlabels = ['Upper (1)', 'Middle (2)', 'Lower (3)']\n#val = sorted(train.Pclass.unique())\nval = [0,1,2] ## this is just a temporary trick to get the label right. \npclass_bar.set_xticklabels(labels);",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "sns.catplot('Pclass', 'Survived', kind='point', data=train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "sns.set(font_scale=1)\ng = sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Pclass\",\n                    data=train, saturation=.5,\n                    kind=\"bar\", ci=None, aspect=.6)\n(g.set_axis_labels(\"\", \"Survival Rate\")\n    .set_xticklabels([\"Men\", \"Women\"])\n    .set_titles(\"{col_name} {col_var}\")\n    .set(ylim=(0, 1))\n    .despine(left=True))  \nplt.subplots_adjust(top=0.8)\ng.fig.suptitle('How many Men and Women Survived by Passenger Class');\n\nfor myaxis in g.axes[0]:\n    for patch in myaxis.patches:\n        label_x = patch.get_x() + patch.get_width()/2  # find midpoint of rectangle\n        label_y = patch.get_y() + patch.get_height()/2\n        myaxis.text(label_x, label_y,\n                    #left - freq below - rel freq wrt population as a percentage\n                    '{:.3%}'.format(patch.get_height()),\n                   horizontalalignment='center', verticalalignment='center')g = sns.factorplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train,\n                   size=6, kind=\"bar\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")\n\nmyaxis = g.ax\nfor patch in myaxis.patches:\n    label_x = patch.get_x() + patch.get_width()/2  # find midpoint of rectangle\n    label_y = patch.get_y() + patch.get_height()/2\n    myaxis.text(label_x, label_y,\n                #left - freq below - rel freq wrt population as a percentage\n                '{:.3%}'.format(patch.get_height()),\n               horizontalalignment='center', verticalalignment='center')\n\n#Another plot that gives the exact same result is as follows: It is good to know different variations.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print_percentage(train,'Embarked',['S','C','Q'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, embarked_bar = plt.subplots(figsize = (8,10))\nsns.barplot(x = \"Embarked\", \n            y = \"Survived\", \n            estimator = np.mean,\n            data=train, \n            ax = embarked_bar,\n            linewidth=2)\nembarked_bar.set_title(\"Passenger Embarked Distribution - Survived vs Non-Survived\", fontsize = 15)\nembarked_bar.set_xlabel(\"Embarked Place\", fontsize = 15);\nembarked_bar.set_ylabel(\"% of Passenger Survived\", fontsize = 15);",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "sns.set(font_scale=1)\ng = sns.catplot(x=\"Pclass\", col=\"Embarked\",\n                    data=train, saturation=.5,\n                    kind=\"count\", ci=None)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "sns.set(font_scale=1)\ng = sns.catplot(x=\"Sex\", col=\"Embarked\",\n                    data=train, saturation=.5,\n                    kind=\"count\", ci=None)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, myaxis = plt.subplots(figsize=(10, 4.5))\n\nsns.kdeplot(data=train[\"Age\"][(train[\"Survived\"] == 0) & (\n    train[\"Age\"].notnull())], kernel='gau', ax=myaxis, color=\"Red\", shade=True, legend=True)\n\n\n# a faster code using loc function is sns.kdeplot(train.loc[(train['Survived'] == 0),'Age'] , color='gray',shade=True,label='not survived')\n\nsns.kdeplot(data=train[\"Age\"][(train[\"Survived\"] == 1) & (\n    train[\"Age\"].notnull())], kernel='gau', ax=myaxis, color=\"Blue\", shade=True, legend=True)\n\nmyaxis.set_xlabel(\"Age\")\nmyaxis.set_ylabel(\"Probability Density\")\nmyaxis.legend([\"Not Survived\", \"Survived\"], loc='upper right')\nmyaxis.set_title(\"Superimposed KDE plot for age of Survived and Not Survived\",\n                 loc='center', fontdict={'fontsize': 16}, color='r')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pal = {1:\"seagreen\", 0:\"gray\"}\ng = sns.FacetGrid(train,size=5, col=\"Sex\", row=\"Survived\", margin_titles=True, hue = \"Survived\",\n                  palette=pal)\ng = g.map(plt.hist, \"Age\", edgecolor = 'white');\ng.fig.suptitle(\"Survived by Sex and Age\", size = 25)\nplt.subplots_adjust(top=0.90)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "g = sns.FacetGrid(train,size=5, col=\"Sex\", row=\"Embarked\", margin_titles=True, hue = \"Survived\",\n                  palette = pal\n                  )\ng = g.map(plt.hist, \"Age\", edgecolor = 'white').add_legend();\ng.fig.suptitle(\"Survived by Sex and Age\", size = 25)\nplt.subplots_adjust(top=0.90)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "null_ages = pd.isnull(train.Age)\nknown_ages = pd.notnull(train.Age)\npreimputation = train.Age[known_ages]\nsns.distplot(preimputation)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, fare = plt.subplots(figsize=(10, 4.5))\n\nsns.kdeplot(data=train.loc[(train['Survived'] == 0),'Fare'], kernel='gau', ax=fare, color=\"Red\", shade=True, legend=True)\n\nsns.kdeplot(data=train.loc[(train['Survived'] == 1),'Fare'], kernel='gau', ax=fare, color=\"Blue\", shade=True, legend=True)\n\nfare.set_xlabel(\"Fare\")\nfare.set_ylabel(\"Probability Density\")\nfare.legend([\"Not Survived\", \"Survived\"], loc='upper right')\nfare.set_title(\"Superimposed KDE plot for Fare of Survived and Not Survived\",\n                 loc='center', fontdict={'fontsize': 16}, color='r')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, fare = plt.subplots(figsize=(20, 5))\nsns.distplot(train.loc[(train['Survived'] == 0),'Fare'], hist=True, color='red', ax=fare)\nsns.distplot(train.loc[(train['Survived'] == 1),'Fare'], hist=True, color='blue', ax=fare)\n\nfare.set_xlabel(\"Fare\")\nfare.set_ylabel(\"Probability Density\")\nfare.legend([\"Not Survived\", \"Survived\"], loc='upper right')\nfare.set_title(\"Superimposed distribution plot for Fare of Survived and Not Survived\",\n                 loc='center', fontdict={'fontsize': 16}, color='r')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train.Parch.value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print_percentage(train,'Parch',[0,1,2,3,4,5,6])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, parch_bar = plt.subplots(figsize = (8,10))\nsns.barplot(x = \"Parch\", \n            y = \"Survived\", \n            estimator = np.mean,\n            data=train, \n            ax = parch_bar,\n            linewidth=2)\nparch_bar.set_title(\"Parch Distribution - Survived vs Non-Survived\", fontsize = 18)\nparch_bar.set_xlabel(\"Parch\", fontsize = 15);\nparch_bar.set_ylabel(\"% of Passenger Survived\", fontsize = 15);",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, myaxis = plt.subplots(figsize=(10, 7.5))\n\nsns.countplot(x = \"Parch\", \n                   hue=\"Survived\",\n                   data = train, \n                   linewidth=2, \n                   palette = {1:\"seagreen\", 0:\"gray\"}, ax = myaxis)\n\n\n## Fixing title, xlabel and ylabel\nmyaxis.set_title(\"Passenger Parch Distribution - Survived vs Not-survived\", fontsize = 20)\nmyaxis.set_xlabel(\"Parch\", fontsize = 15);\nmyaxis.set_ylabel(\"Number of Passenger Survived\", fontsize = 15)\nmyaxis.legend([\"Not Survived\", \"Survived\"], loc = 'upper right')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train.SibSp.value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print_percentage(train,'SibSp',[0,1,2,3,4,5,8])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, parch_bar = plt.subplots(figsize = (8,10))\nsns.barplot(x = \"SibSp\", \n            y = \"Survived\", \n            estimator = np.mean,\n            data=train, \n            ax = parch_bar,\n            linewidth=2)\nparch_bar.set_title(\"Siblings Distribution - Survived vs Non-Survived\", fontsize = 18)\nparch_bar.set_xlabel(\"SibSp\", fontsize = 15);\nparch_bar.set_ylabel(\"% of Passenger Survived\", fontsize = 15);",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, myaxis = plt.subplots(figsize=(10, 7.5))\n\nsns.countplot(x = \"SibSp\", \n                   hue=\"Survived\",\n                   data = train, \n                   linewidth=2, \n                   palette = {1:\"seagreen\", 0:\"gray\"}, ax = myaxis)\n\n\n## Fixing title, xlabel and ylabel\nmyaxis.set_title(\"Siblings Distribution - Survived vs Not-survived\", fontsize = 20)\nmyaxis.set_xlabel(\"Siblings\", fontsize = 15);\nmyaxis.set_ylabel(\"Number of Passenger Survived\", fontsize = 15)\nmyaxis.legend([\"Not Survived\", \"Survived\"], loc = 'upper right')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print('Amount of missing data in Fare for training set:', train.Fare.isnull().sum())\nprint('Amount of missing data in Fare for test set:', Test.Fare.isnull().sum())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Test[Test['Fare'].isnull()]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "median_fare = Test.groupby(['Pclass', 'Parch']).Fare.median()[3][0]\n# Filling the missing value in Fare with the median Fare of 3rd class passenger who has Parch 0.\nTest['Fare'] = Test['Fare'].fillna(median_fare)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, fare = plt.subplots(figsize=(20, 6.6))\nsns.distplot(train.Fare, hist=False,  color='red', label = \"Training Data\",ax=fare)\nsns.distplot(Test.Fare, hist=False, label = \"Test Data\", color='blue', ax=fare)\nprint('Amount of missing data in Embarked for train:', train.Embarked.isnull().sum())\nprint('Amount of missing data in Embarked for test:', Test.Embarked.isnull().sum())\nfare.set_xlabel(\"Fare\")\nfare.set_ylabel(\"Probability Density\")\nfare.legend([\"Training Data\", \"Test Data\"], loc='upper right')\nfare.set_title(\"Superimposed distribution plot for Fare of Training set vs Test set\",\n                 loc='center', fontdict={'fontsize': 16}, color='r')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print('Amount of missing data in Embarked for train:', train.Embarked.isnull().sum())\nprint('Amount of missing data in Embarked for test:', Test.Embarked.isnull().sum())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train[train['Embarked'].isnull()]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train['Embarked'] = train['Embarked'].fillna('S')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print('Amount of missing data in Age for train:', train.Age.isnull().sum())\nprint('Amount of missing data in Age for test:', Test.Age.isnull().sum())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, myaxis = plt.subplots(figsize=(10, 4.5))\n\npreimputation=sns.kdeplot(data=train[\"Age\"][(train[\"Survived\"] == 0) & (\n    train[\"Age\"].notnull())], kernel='gau', ax=myaxis, color=\"Red\", shade=True, legend=True)\n\n\n# a faster code using loc function is sns.kdeplot(train.loc[(train['Survived'] == 0),'Age'] , color='gray',shade=True,label='not survived')\n\npreimputation=sns.kdeplot(data=train[\"Age\"][(train[\"Survived\"] == 1) & (\n    train[\"Age\"].notnull())], kernel='gau', ax=myaxis, color=\"Blue\", shade=True, legend=True)\n\nmyaxis.set_xlabel(\"Age\")\nmyaxis.set_ylabel(\"Probability Density\")\nmyaxis.legend([\"Not Survived\", \"Survived\"], loc='upper right')\nmyaxis.set_title(\"Superimposed KDE plot for age of Survived and Not Survived\",\n                 loc='center', fontdict={'fontsize': 16}, color='r')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "copy5 = train.copy()\nmissing_age_rows2 = copy5.Age.isna()\nmissing_age_rows2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "age_by_pclass_SibSp = copy5.groupby(['Pclass', 'SibSp']).median()['Age']\nage_by_pclass_SibSp",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "age_by_pclass_SibSp[1].index.tolist()\nage_by_pclass_SibSp[3][8] = age_by_pclass_SibSp[3][5] #since no age values for pclass 3 and sibsp 8 we fill it with\n#pclass 3 and sibsp5\nage_by_pclass_SibSp",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "for pclass in range(1, 4):\n    for siblings in age_by_pclass_SibSp[pclass].index.tolist():\n        print('Median age of Pclass {} with {} siblings: {}'.format(pclass, siblings, age_by_pclass_SibSp[pclass][siblings]))\nprint('Median age of all passengers: {}'.format(copy5['Age'].median()))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "copy5['Age'] = copy5.groupby(['Pclass', 'SibSp'])[\n    'Age'].apply(lambda x: x.fillna(x.median()))\n# this line is the single code that we need to fill up all the \n#missing values: powerful one liner from \n#https://www.kaggle.com/gunesevitan/advanced-feature-engineering-tutorial-with-titanic.\n\n#however do not forget that the above line of code does not take care of the 7 missing NaN values from passengers\n#from Pclass 3 & SibSp 8. So we fill in the remaining 7 missing values to be age 11.\n\ncopy5['Age'] = copy5.Age.fillna(11) #think this step cause no values for NA value.\ncopy5.info()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, myaxis = plt.subplots(figsize=(20, 4.5))\n\npreimputation=sns.kdeplot(data=train[\"Age\"][(train[\"Survived\"] == 0) & (\n    train[\"Age\"].notnull())], kernel='gau', ax=myaxis, color=\"Blue\", shade=True, legend=True)\n\n\n# a faster code using loc function is sns.kdeplot(train.loc[(train['Survived'] == 0),'Age'] , color='gray',shade=True,label='not survived')\n\n\nafterimputation=sns.kdeplot(data=copy5[\"Age\"][(copy5[\"Survived\"] == 0) & (\n    copy5[\"Age\"].notnull())], kernel='gau', ax=myaxis, color=\"maroon\", shade=True, legend=True)\n\n\n# a faster code using loc function is sns.kdeplot(train.loc[(train['Survived'] == 0),'Age'] , color='gray',shade=True,label='not survived')\n\n\nmyaxis.set_xlabel(\"Age\")\nmyaxis.set_ylabel(\"Probability Density\")\nmyaxis.legend([\"pre\", \"after\"], loc='upper right')\nmyaxis.set_title(\"Superimposed KDE plot for age of not survived: pre-imputation vs after-imputation\",\n                 loc='center', fontdict={'fontsize': 16}, color='r')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, myaxis = plt.subplots(figsize=(20, 4.5))\n\npreimputation=sns.kdeplot(data=train[\"Age\"][(train[\"Survived\"] == 1) & (\n    train[\"Age\"].notnull())], kernel='gau', ax=myaxis, color=\"Blue\", shade=True, legend=True)\n\n\n# a faster code using loc function is sns.kdeplot(train.loc[(train['Survived'] == 0),'Age'] , color='gray',shade=True,label='not survived')\n\nafterimputation=sns.kdeplot(data=copy5[\"Age\"][(copy5[\"Survived\"] == 1) & (\n    copy5[\"Age\"].notnull())], kernel='gau', ax=myaxis, color=\"maroon\", shade=True, legend=True)\n\nmyaxis.set_xlabel(\"Age\")\nmyaxis.set_ylabel(\"Probability Density\")\nmyaxis.legend([\"pre\", \"after\"], loc='upper right')\nmyaxis.set_title(\"Superimposed KDE plot for age of survived: pre-imputation vs after-imputation\",\n                 loc='center', fontdict={'fontsize': 16}, color='r')\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "copy2 = train.copy() #wanna work with copy here so dont mess up the original data values.\ncopy2['Age'].fillna(copy2['Age'].median(),inplace = True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, myaxis = plt.subplots(figsize=(20, 4.5))\n\npreimputation=sns.kdeplot(data=train[\"Age\"][(train[\"Survived\"] == 0) & (\n    train[\"Age\"].notnull())], kernel='gau', ax=myaxis, color=\"Blue\", shade=True, legend=True)\n\n\nmedian1=sns.kdeplot(data=copy2[\"Age\"][(copy2[\"Survived\"] == 0) & (\n    copy2[\"Age\"].notnull())], kernel='gau', ax=myaxis, color=\"maroon\", shade=True, legend=True)\n\n\n\nmyaxis.set_xlabel(\"Age\")\nmyaxis.set_ylabel(\"Probability Density\")\nmyaxis.legend([\"pre\", \"after\"], loc='upper right')\nmyaxis.set_title(\"Superimposed KDE plot for age of not survived: pre-imputation vs after-imputation\",\n                 loc='center', fontdict={'fontsize': 16}, color='r')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "figure, myaxis = plt.subplots(figsize=(20, 4.5))\n\n\n\n\npreimputation=sns.kdeplot(data=train[\"Age\"][(train[\"Survived\"] == 1) & (\n    train[\"Age\"].notnull())], kernel='gau', ax=myaxis, color=\"Blue\", shade=True, legend=True)\n\n\n\n\n\nmedian1=sns.kdeplot(data=copy2[\"Age\"][(copy2[\"Survived\"] == 1) & (\n    copy2[\"Age\"].notnull())], kernel='gau', ax=myaxis, color=\"maroon\", shade=True, legend=True)\n\nmyaxis.set_xlabel(\"Age\")\nmyaxis.set_ylabel(\"Probability Density\")\nmyaxis.legend([\"pre\", \"after\"], loc='upper right')\nmyaxis.set_title(\"Superimposed KDE plot for age of survived: pre-imputation vs after-imputation\",\n                 loc='center', fontdict={'fontsize': 16}, color='r')\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train = copy5",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "test_age_by_pclass_SibSp = Test.groupby(['Pclass', 'SibSp']).median()['Age']\ntest_age_by_pclass_SibSp\nTest['Age'] = Test.groupby(['Pclass', 'SibSp'])['Age'].apply(lambda x: x.fillna(x.median()))\nTest.info()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from collections import Counter\n\ndef detect_outliers(df, n, features):\n    outliers_indices = [] #create a empty list to keep track of the passenger row number.\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.nanpercentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.nanpercentile(df[col], 75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step)\n                              | (df[col] > Q3 + outlier_step)].index\n        \n        #print(df[(df[col] < Q1 - outlier_step)print(col,Q1-outlier_step,Q3+outlier_step)\n        # append the found outlier indices for col to the list of outlier indices\n        outliers_indices.extend(outlier_list_col)\n        \n    #print(outliers_indices)\n    \n    # select observations containing more than 2 outliers\n    outliers_indices = Counter(outliers_indices)\n    multiple_outliers = list(k for k, v in outliers_indices.items() if v > n)\n    #print(outliers_indices)\n    \n    return multiple_outliers\n\n\nOutliers_to_drop = detect_outliers(train, 2, [\"Age\", \"SibSp\", \"Parch\", \"Fare\"])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Outliers_to_drop\n\ntrain.loc[Outliers_to_drop]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def outlier_treatment(datacolumn):\n    sorted(datacolumn) #must sort data first since we dealing with quartile ranges.\n    Q1, Q3 = np.nanpercentile(datacolumn,[25,75])\n    IQR = Q3-Q1\n    lower_range = Q1-(1.5*IQR)\n    upper_range = Q3+ (1.5*IQR)\n    return lower_range, upper_range\n\n\n\nprint('Upper and Lower bound for Age:',outlier_treatment(train.Age), sep = '\\n')\nprint('Upper and Lower bound for Fare:',outlier_treatment(train.Fare), sep = '\\n')\nprint('Upper and Lower bound for Parch:',outlier_treatment(train.Parch), sep = '\\n')\nprint('Upper and Lower bound for Siblings:',outlier_treatment(train.SibSp), sep = '\\n')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print('Number of Unique values for Name is', len(train.Name.unique()))\nprint('Number of Unique values for PassengerID is', len(train.PassengerId.unique()))\nprint('Number of Unique values for Fare is', len(train.Fare.unique()))\nprint('Number of Unique values for Survived is', len(train.Survived.unique()))\nprint('Number of Unique values for Pclass is', len(train.Pclass.unique()))\nprint('Number of Unique values for Parch is', len(train.Parch.unique()))\nprint('Number of Unique values for SibSp is', len(train.SibSp.unique()))\nprint('Number of Unique values for Embarked is', len(train.Embarked.unique()))\nprint('Number of Unique values for Cabin is', len(train.Cabin.unique()))\nprint('Number of Unique values for Sex is', len(train.Sex.unique()))\nprint('Number of Unique values for Ticket is', len(train.Ticket.unique()))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train.drop([\"PassengerId\"],inplace=True,axis=1)\nTest.drop([\"PassengerId\"],inplace=True,axis=1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "groupby_pclass_ticket= train.groupby([\"Pclass\",\"Ticket\"])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train.drop([\"Ticket\"],inplace=True,axis=1)\nTest.drop([\"Ticket\"],inplace=True,axis=1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train.Name.head(20)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def name_sep(data):\n    families=[]\n    titles = []\n    new_name = []\n    #for each row in dataset:\n    for i in range(len(data)):\n        name = data.iloc[i]\n        # extract name inside brakets into name_bracket:\n        if '(' in name:\n            name_no_bracket = name.split('(')[0] \n        else:\n            name_no_bracket = name\n            \n        family = name_no_bracket.split(\",\")[0]\n        title = name_no_bracket.split(\",\")[1].strip().split(\" \")[0]\n        \n        #remove punctuations accept brackets:\n        for c in string.punctuation:\n            name = name.replace(c,\"\").strip()\n            family = family.replace(c,\"\").strip()\n            title = title.replace(c,\"\").strip()\n            \n        families.append(family)\n        titles.append(title)\n        new_name.append(name)\n    \n            \n    return families, titles, new_name ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train['Surname'], train['Title'], train['Newname']  = name_sep(train.Name)\nTest['Surname'], Test['Title'], Test['Newname'] = name_sep(Test.Name)\ntrain.head()\ntrain.Title.value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train['Title'] = train['Title'].replace(['Ms', 'Mlle'],'Miss')\ntrain['Title'] = train['Title'].replace(['Mme'],'Mrs')\ntrain['Title'] = train['Title'].replace(['Dr','Rev','the','Jonkheer','Lady','Sir', 'Don'],'Nobles')\ntrain['Title'] = train['Title'].replace(['Major','Col', 'Capt'],'Navy')\ntrain.Title.value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "sns.barplot(x = 'Title', y = 'Survived', data = train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "nobles_survival = train[train.Title == \"Nobles\"].groupby(['Sex']).Survived.value_counts()\nnobles_survival",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Test.Title.value_counts()\n\nTest['Title'] = Test['Title'].replace(['Ms','Dona'],'Miss')\nTest['Title'] = Test['Title'].replace(['Dr','Rev'],'Nobles')\nTest['Title'] = Test['Title'].replace(['Col'],'Navy')\nTest.Title.value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print('Missing values in Train set:', train.Cabin.isnull().sum())\nprint('Missing values in Test set:', Test.Cabin.isnull().sum())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train.Cabin.value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def cabin_sep(data_cabin):\n    cabin_type = []\n\n    for i in range(len(data_cabin)):\n\n            if data_cabin.isnull()[i] == True: \n                cabin_type.append('M') #missing cabin = M \n            else:    \n                cabin = data_cabin[i]\n                cabin_type.append(cabin[:1]) \n            \n    return cabin_type\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train['Cabin'] = train['Cabin'].fillna('M').astype(str).apply(lambda cabin: cabin[0])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "idx = train[train['Cabin'] == 'T'].index\ntrain.loc[idx, 'Cabin'] = 'A'\ntrain.Cabin.value_counts()\nTest['Cabin'] = Test['Cabin'].fillna('M').astype(str).apply(lambda cabin: cabin[0])\nTest.Cabin.value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "train_categorical_features = ['Pclass', 'Sex','Title','Cabin', 'Embarked']\n\n# No need to use sklearn's encoders\n# pandas has a pandas.get_dummies() function that takes in a series\n#     and returns a HOT encoded dataframe of that series\n#     use the add_prefix() method of dataframe to add the feature name in front of the category name\n#     then join the dataframe sideways (similar to pd.concat([train, dummies], axis=1))\nfor feature in train_categorical_features:\n    dummies = pd.get_dummies(train[feature]).add_prefix(feature + '_')\n    train = train.join(dummies)\n    \ntrain",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "test_categorical_features = ['Pclass', 'Sex','Title', 'Cabin', 'Embarked']\n\n# No need to use sklearn's encoders\n# pandas has a pandas.get_dummies() function that takes in a series\n#     and returns a HOT encoded dataframe of that series\n#     use the add_prefix() method of dataframe to add the feature name in front of the category name\n#     then join the dataframe sideways (similar to pd.concat([train, dummies], axis=1))\nfor feature in test_categorical_features:\n    dummies = pd.get_dummies(Test[feature]).add_prefix(feature + '_')\n    Test = Test.join(dummies)\n    \nTest",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import learning_curve,GridSearchCV\nfrom sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.formula.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_scorefrom sklearn.metrics import confusion_matrix\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n#import xgboost as xgb\nfrom sklearn.metrics import roc_curve, auc\nimport scikitplot as skplt #conda install -c conda-forge scikit-plot\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import mean_absolute_error, accuracy_score\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "drop_column = ['Pclass','Name','Sex','Cabin', 'Embarked','Surname','Title','Newname']\ntrain.drop(drop_column, axis=1, inplace = True)\n\ndrop_column = ['Pclass','Name','Sex','Cabin', 'Embarked','Surname','Title','Newname']\nTest.drop(drop_column, axis=1, inplace = True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "original_train_set_without_survived = train.drop(\"Survived\", axis=1)\norginal_train_set_with_only_survived = train[\"Survived\"]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "x_train, x_test, y_train, y_test = train_test_split(\n    original_train_set_without_survived, orginal_train_set_with_only_survived, train_size=0.8, test_size=0.2, random_state=0)\nprint(x_train.shape, y_train.shape)\nprint(x_test.shape, y_test.shape)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n\n## transforming \"train_x\"\nx_train = sc.fit_transform(x_train)\n## transforming \"test_x\"\nx_test = sc.transform(x_test)\n\n## transforming \"The testset\"\nTest = sc.transform(Test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "logreg = LogisticRegression()\n\n## fit the model with \"train_x\" and \"train_y\"\nlogreg.fit(x_train,y_train)\n#Alternatively also can use\n#print (\"So, Our accuracy Score is: {}\".format(round(logreg.score(x_test,y_test),8)))\n\n## Once the model is trained we want to find out how well the model is performing, so we test the model. \n## we use \"test_x\" portion of the data(this data was not used to fit the model) to predict model outcome. \ny_pred = logreg.predict(x_test)\n\n## Once predicted we save that outcome in \"y_pred\" variable.\n## Then we compare the predicted value( \"y_pred\") and actual value(\"test_y\") to see how well our model is performing. \n\nprint (\"So, Our accuracy Score is: {}\".format(round(accuracy_score(y_test,y_pred),8)))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def confusion_matrix_model(model_used):\n    cm=confusion_matrix(y_test,model_used.predict(x_test))\n    col=[\"Predicted Dead\",\"Predicted Survived\"]\n    cm=pd.DataFrame(cm)\n    cm.columns=[\"Predicted Dead\",\"Predicted Survived\"]\n    cm.index=[\"Actual Dead\",\"Actual Survived\"]\n    cm[col]=np.around(cm[col].div(cm[col].sum(axis=1),axis=0),decimals=2)\n    return cm\n\n\n\nconfusion_matrix_model(logreg)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import roc_curve, auc\n#plt.style.use('seaborn-pastel')\ny_score = logreg.decision_function(x_test) #y_pred_proba = logreg.predict_proba(X_test)[:, 1] same as this?\n\nFPR, TPR, THR = roc_curve(y_test, y_score) #[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba) same as this\nROC_AUC = auc(FPR, TPR)\nprint (logreg.__class__.__name__+\" auc is %2.8f\" % ROC_AUC) #Gives AUC score.\n\n\n#Next is draw roc graph.\nplt.figure(figsize =[10,9])\nplt.plot(FPR, TPR, label= 'ROC curve(area = %0.2f)'%ROC_AUC, linewidth= 4)\nplt.plot([0,1],[0,1], 'k--', linewidth = 4)\nplt.xlim([0.0,1.0])\nplt.ylim([0.0,1.05])\nplt.xlabel('False Positive Rate', fontsize = 17)\nplt.ylabel('True Positive Rate', fontsize = 17)\nplt.title('ROC for Logistic Regression (Titanic)', fontsize= 17)\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import precision_recall_curve\n\ny_score = logreg.decision_function(x_test)\n\nprecision, recall, _ = precision_recall_curve(y_test, y_score)\nPR_AUC = auc(recall, precision)\n\nplt.figure(figsize=[11,9])\nplt.plot(recall, precision, label='PR curve (area = %0.2f)' % PR_AUC, linewidth=4)\nplt.xlabel('Recall', fontsize=18)\nplt.ylabel('Precision', fontsize=18)\nplt.title('Precision Recall Curve for Titanic survivors', fontsize=18)\nplt.legend(loc=\"lower right\")\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "x = original_train_set_without_survived\ny = orginal_train_set_with_only_survived",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "x = sc.fit_transform(x)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def Acc_score(model):\n    return np.mean(cross_val_score(model,x,y,cv=k_fold,scoring=\"accuracy\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "logreg2=LogisticRegression()\n\nprint(\"Accuracy Scores: \" + format(cross_val_score(logreg2,x,y,cv=k_fold,scoring=\"accuracy\")))\nprint(\" \") #leave empty line\nprint(\"Mean Accuracy Score: \" + str(Acc_score(logreg2)))\nprint(\" \")\nprint(\"Standard Deviation:\", cross_val_score(logreg2,x,y,cv=k_fold,scoring=\"accuracy\").std())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "scores_auc = cross_val_score(logreg2, x, y, cv=k_fold, scoring='roc_auc')\n#Notice scoring = roc_auc now.  https://scikit-learn.org/stable/modules/model_evaluation.html\nprint(\"AUC score for 10 fold Cross Validation:\", scores_auc)\nprint(\" \")\nprint(\"Mean AUC score for 10 fold Cross Validation:\", scores_auc.mean())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def plt_roc_curve(name, model, cv_x_test, cv_y_test, has_proba=True):\n    if has_proba:\n        fpr,tpr,thr=skplt.metrics.roc_curve(cv_y_test,model.predict_proba(cv_x_test)[:,1])\n    else:\n        fpr,tpr,thr=skplt.metrics.roc_curve(cv_y_test,model.decision_function(cv_x_test))\n    auc= skplt.metrics.auc(fpr,tpr) #x axis is fpr, y axis is tpr\n\n    plt.plot(fpr,tpr,label='ROC curve for %s (AUC = %0.8f)' % (name, auc))\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim((0,1))\n    plt.ylim((0,1))\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"ROC Curve\")\n    plt.legend(loc=\"lower right\")\n    #plt.show()\n    return fpr, tpr, auc",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def run_k_fold(modeller, no_of_folds):\n    scores = []\n    mean_fpr = np.linspace(0, 1, 100)\n    tprs = []\n    aucs = []\n    plt.figure(figsize =[10,9])\n    \n    k_fold = KFold(n_splits=no_of_folds, shuffle=True, random_state=0)\n    fold = 1\n    # the below line's x, y is from outside just now.\n    #k_fold.split gives you all 10 rounds in a list of tuples [round1, round2,...]\n    #each round consists of the rows to be in the training set (90%) and the rows to be in \n    #the test set (10%) for that round. \n    for rounds in k_fold.split(x, y): #don't use round as it is a in built function\n        train_rows = rounds[0]\n        test_rows  = rounds[1]\n        CV_x_train = x[train_rows]\n        CV_y_train = y[train_rows]\n        CV_x_test = x[test_rows]\n        CV_y_test = y[test_rows]\n        model = modeller()model.fit(CV_x_train, CV_y_train)\n        scores.append(model.score(CV_x_test, CV_y_test))\n        curr_fpr, curr_tpr, curr_auc = plt_roc_curve(\n            'log reg fold ' + str(fold), model, CV_x_test, CV_y_test)\n\n        tprs.append(np.interp(mean_fpr, curr_fpr, curr_tpr))\n        tprs[-1][0] = 0.0\n        roc_auc = auc(curr_fpr, curr_tpr)\n        aucs.append(roc_auc)\n        fold += 1\n\n    mean_tpr = np.mean(tprs, axis=0)\n    mean_tpr[-1] = 1.0\n    mean_auc = auc(mean_fpr, mean_tpr)\n    std_auc = np.std(aucs)  # popn std dev?\n    plt.plot(mean_fpr, mean_tpr, color='b',\n             label=r'Mean ROC (AUC = %0.8f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n             lw=2, alpha=.8)\n\n    std_tpr = np.std(tprs, axis=0)tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                     label=r'$\\pm$ 1 std. dev.')\n    \n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return np.mean(scores)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "accuracy_score = run_k_fold(LogisticRegression, 10)\nprint(\"Accuracy Score:\", accuracy_score)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nmax_depth = range(1,30)\n#max_feature = list(range(1,x.shape[1]+1)) #dynamic coding\nmax_feature = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,'auto'] #how one knows start at 21\n\n\ncriterion=[\"entropy\", \"gini\"]\n\nparam = {'max_depth':max_depth, \n         'max_features':max_feature, \n         'criterion': criterion}\ngrid = GridSearchCV(DecisionTreeClassifier(random_state=42), \n                                param_grid = param, \n                                 verbose=False, \n                                 cv=KFold(n_splits=10, shuffle=True, random_state=42),\n                                n_jobs = -1)\ngrid.fit(x, y) \n\nprint( grid.best_params_)\nprint(\" \")\nprint (grid.best_score_)\nprint(\" \")\nprint (grid.best_estimator_)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "dectree_grid = grid.best_estimator_\n## using the best found hyper paremeters to get the score. \ndectree_grid.score(x,y)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\n\nrf_model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n                       max_depth=9, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=16,\n                       min_weight_fraction_leaf=0.0, n_estimators=140,\n                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n                       warm_start=True)\n\nrf_model.fit(x,y)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#print(\"%.3f\" % rf_model.oob_score_)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "rf_model.score(x,y)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Test = sc.fit_transform(Test)\nTest1 = pd.read_csv(\"../input/titanic/test.csv\")\n\noutput3 = pd.DataFrame({\"PassengerId\": Test1.PassengerId, \"Survived\":rf_model.predict(Test)})\noutput3.PassengerId = output3.PassengerId.astype(int)\noutput3.Survived = output3.Survived.astype(int)\n\noutput3.to_csv(\"output3.csv\", index=False)\nprint(\"Your submission was successfully saved!\")\noutput3.head(10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}